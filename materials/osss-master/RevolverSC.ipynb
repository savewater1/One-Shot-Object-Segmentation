{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RevolverSC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "U6rejPAl7Xxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The dataset.tar file should be extracted in the same directory as the notebook\n",
        "# Importing data from dataset\n",
        "from dataset_generator import get_data_file_lists, get_dataset, normalize_n_structure_data\n",
        "trainf, testf, ktestf = get_data_file_lists('dataset', 4, [\"tomato\", \"toothpaste\"], [\"cap_3\", \"food_box_3\", \"soda_can_2\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJxJCu4u8KBU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalizing images\n",
        "train_ds = get_dataset(trainf).map(normalize_n_structure_data)\n",
        "test_ds = get_dataset(testf).map(normalize_n_structure_data)\n",
        "ktest_ds = get_dataset(ktestf).map(normalize_n_structure_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qtgl1wCO6hFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, \\\n",
        "Lambda, multiply, concatenate, InputLayer, UpSampling2D, Layer, Concatenate, ZeroPadding2D, Conv2DTranspose\n",
        "import keras.backend as K\n",
        "from keras import Input\n",
        "from keras.initializers import Constant, RandomNormal\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.models import Model, Sequential\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkzckYWP8Yfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preprocess_fn = lambda a,b,c,d,e,f: (\n",
        "    a,\n",
        "    tf.pad(1-c, ((0,31), (0,31), (0,0)))[:,:,0:1],\n",
        "    tf.pad(c, ((0,31), (0,31), (0,0)))[:,:,0:1],\n",
        "    tf.image.resize_image_with_pad(d, 224, 224),\n",
        "    e,\n",
        "    tf.image.resize_image_with_pad(f, 224, 224))\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(preprocess_fn).batch(4).repeat()\n",
        "test_ds = test_ds.map(preprocess_fn).batch(1)\n",
        "ktest_ds = ktest_ds.map(preprocess_fn).batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0_HArvmF43c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_iter = tf.data.Iterator.from_structure(test_ds.output_types, test_ds.output_shapes)\n",
        "simg_batch, smskn_batch, smskp_batch, qimg_batch, qdepth_batch, qmsk_batch = data_iter.get_next()\n",
        "init_training = data_iter.make_initializer(train_ds)\n",
        "init_testing = data_iter.make_initializer(test_ds)\n",
        "init_ktesting = data_iter.make_initializer(ktest_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGf4z7M36hFk",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of Classes\n",
        "# Since the images in our dataset contains object belonging to only one class per image num_classes is 1.\n",
        "# We have written the code to implement multi-class segmentation, which will be used in future improvements, but decided not to include it here.\n",
        "num_classes = 1  #@param{type:\"slider\", min:1, max:5}\n",
        "\n",
        "# Feature Dimension - 512 for light version of the head and 4096 when using fully convolutionalized VGG16 network\n",
        "feat_dim = 512  #@param{type:\"slider\", min:256, max:4096}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ZX1w8-Z6hFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The feature extractor; VGG16, pretrained on ILSVRC\n",
        "vgg = VGG16(include_top = False, weights = 'imagenet', input_shape = (224,224,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XidOD836hFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VGG summary\n",
        "vgg.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJUSqQWY6hFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note: Use this function when fully convolutionalized version of VGG16 is to be used as feature extractor. \n",
        "# When using this, set feat_dim to 4096\n",
        "\n",
        "# def get_encoder(model):\n",
        "#     \"\"\"\n",
        "#     https://stackoverflow.com/questions/41161021/how-to-convert-a-dense-layer-to-an-equivalent-convolutional-layer-in-keras\n",
        "#     Recast `modules` into fully convolutional form.\n",
        "#     The conversion transfers weights and infers kernel sizes from the\n",
        "#     `input_size` and modules' action on it.\n",
        "#     n.b. This only handles the conversion of linear/fully-connected modules,\n",
        "#     although other module types could require conversion for correctness.\n",
        "#     \"\"\"\n",
        "#     model_layers = []\n",
        "#     for layer in model.layers:\n",
        "\n",
        "#         if \"Flatten\" in str(layer):\n",
        "#             flattened_ipt = True\n",
        "#             f_dim = layer.input_shape\n",
        "#             continue\n",
        "\n",
        "#         elif \"Dense\" in str(layer):\n",
        "#             input_shape = layer.input_shape\n",
        "#             output_dim =  layer.get_weights()[1].shape[0]\n",
        "#             W,b = layer.get_weights()\n",
        "\n",
        "#             if flattened_ipt:\n",
        "#                 shape = (f_dim[1],f_dim[2],f_dim[3],output_dim)\n",
        "#                 new_W = W.reshape(shape)\n",
        "#                 new_layer = Conv2D(output_dim,\n",
        "#                                           (f_dim[1],f_dim[2]),\n",
        "#                                           strides=(1,1),\n",
        "#                                           activation='relu',\n",
        "#                                           padding='valid',\n",
        "#                                           weights=[new_W,b])\n",
        "#                 flattened_ipt = False\n",
        "\n",
        "#             else:\n",
        "#                 shape = (1,1,input_shape[1],output_dim)\n",
        "#                 new_W = W.reshape(shape)\n",
        "#                 new_layer = Conv2D(output_dim,\n",
        "#                                           (1,1),\n",
        "#                                           strides=(1,1),\n",
        "#                                           activation='relu',\n",
        "#                                           padding='valid',\n",
        "#                                           weights=[new_W,b])\n",
        "\n",
        "\n",
        "#         else:\n",
        "#             new_layer = layer\n",
        "\n",
        "#         model_layers.append(new_layer)\n",
        "    \n",
        "#     return model_layers[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpLVR2LD6hFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bilinear_kernel(size, normalize=False):\n",
        "    \"\"\"\n",
        "    Make a 2D bilinear kernel suitable for upsampling/downsampling with\n",
        "    normalize=False/True. The kernel is size x size square.\n",
        "    Take\n",
        "        size: kernel size (square)\n",
        "        normalize: whether kernel sums to 1 (True) or not\n",
        "    Give\n",
        "        kernel: np.array with bilinear kernel coefficient\n",
        "    \"\"\"\n",
        "    factor = (size + 1) // 2\n",
        "    if size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:size, :size]\n",
        "    kernel = (1 - abs(og[0] - center) / factor) * \\\n",
        "             (1 - abs(og[1] - center) / factor)\n",
        "    if normalize:\n",
        "        kernel /= kernel.sum()\n",
        "    return kernel.astype('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AoMv5Jvg6hF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Interpolator(Layer):\n",
        "    \"\"\"\n",
        "    Transposed Convolution layer with fixed bilinear kernel. Used for upsampling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filters, rate, odd = False, normalize = False, **kwargs):\n",
        "        self.filter = filters\n",
        "        self.strides = (rate, rate)\n",
        "        self.kernel_size = rate*2\n",
        "        if odd:\n",
        "            self.kernel_size -= 1\n",
        "        bk = bilinear_kernel(self.kernel_size, normalize)\n",
        "        self.ini = np.repeat(np.repeat(bk[:,:,None,None], self.filter, axis = -2), self.filter, axis = -1).astype('float64')\n",
        "        super(Interpolator, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(self.kernel_size, self.kernel_size, self.filter, self.filter),\n",
        "                                      initializer=Constant(self.ini),\n",
        "                                      trainable=False)\n",
        "        super(Interpolator, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        return K.conv2d_transpose(\n",
        "                x,\n",
        "                self.kernel,\n",
        "                output_shape = (tf.shape(x)[0], (tf.shape(x)[1]-1)*self.strides[0] + self.kernel_size, \\\n",
        "                                (tf.shape(x)[2]-1)*self.strides[1] + self.kernel_size, self.filter),\n",
        "                strides=self.strides,\n",
        "                data_format='channels_last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HNvR9m56hF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Downsampler(Layer):\n",
        "    \"\"\"\n",
        "    Convolution layer with fixed bilinear kernel. Used for downsampling.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, filters, rate, odd, normalize = True, **kwargs):\n",
        "        self.filter = filters\n",
        "        self.strides = (rate, rate)\n",
        "        self.kernel_size = rate * 2\n",
        "        if odd:\n",
        "            self.kernel_size -= 1\n",
        "        bk = bilinear_kernel(self.kernel_size, normalize)\n",
        "        self.ini = np.repeat(np.repeat(bk[:,:,None,None], self.filter, axis = -2), self.filter, axis = -1).astype('float64')\n",
        "        super(Downsampler, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(self.kernel_size, self.kernel_size, self.filter, self.filter),\n",
        "                                      initializer=Constant(self.ini),\n",
        "                                      trainable=False)\n",
        "        super(Downsampler, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        return K.conv2d(\n",
        "                x,\n",
        "                self.kernel,\n",
        "                strides=self.strides,\n",
        "                data_format='channels_last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYusu2qQ6hF7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# When using fully convolutionalized version of VGG16, use the convolutional base and FC6 layer with added Dropout layer at the end.\n",
        "# Encoder Network(Light Version) - VGG Convolution base + FC6\n",
        "# Adding a pad layer to get output of desired shape (6x6xC)\n",
        "pad_layer = ZeroPadding2D(padding=(81,81))\n",
        "layers = vgg.layers\n",
        "layers.insert(0, pad_layer)\n",
        "encoder_input = x = Input(shape=(224,224,3))\n",
        "for i, layer in enumerate(layers):\n",
        "    x = layer(x)\n",
        "x = Conv2D(512, (7,7), padding = 'valid', name = 'fc6', kernel_initializer = RandomNormal(mean=0, stddev=0.001), bias_initializer='zeros', activation='relu')(x)\n",
        "encoder_output = Dropout(0.5)(x)\n",
        "encoder = Model(encoder_input, encoder_output)\n",
        "\n",
        "# Clearing up memory\n",
        "del layers\n",
        "del vgg\n",
        "\n",
        "# Feature Extracto Summary\n",
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUzRdKJz6hF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classification head\n",
        "# Note: The small fully convolutional network used to produce segmentation mask from fused query features and guide\n",
        "head_input = Input(shape = (None, None, feat_dim*2), name = 'Head_Input')\n",
        "x = Conv2D(feat_dim*2, (1, 1), activation='relu', name = 'Head_Conv1', kernel_initializer = RandomNormal(mean=0, stddev=0.001))(head_input)\n",
        "x = Dropout(0.5, name = 'Head_drop1')(x)\n",
        "score = Conv2D(num_classes, (1,1), name = 'Head_conv2', kernel_initializer='zeros', bias_initializer='zeros')(x)\n",
        "head = Model(head_input, score)\n",
        "head.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stzT82B26hGA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## IMPORTANT!!\n",
        "Annotation shape: BatchxClassesxHxW in channel first format  \n",
        "\n",
        "Batch x H x W x Classes for us"
      ]
    },
    {
      "metadata": {
        "id": "8bIx97pA6hGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mask_feat(x, mask, scale = True):\n",
        "    \"\"\"\n",
        "    Helper function used to apply downsampled support mask to support features.\n",
        "    \"\"\"\n",
        "    x_size, mask_size = x.shape, mask.shape\n",
        "    if x_size[1:-1] != mask_size[1:-1]:\n",
        "        raise ValueError(\"Shape mismatch. Feature is {}, but mask is {}\".format(x_size, mask_size))\n",
        "    if scale:\n",
        "        x = tf.multiply(x, mask)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8fw9WULLV3z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For single class annotation\n",
        "def get_combined_feat(qfeats, sfeatures, pos_anno, neg_anno, nc, update = False):    \n",
        "    \"\"\"\n",
        "    Helper function used to fuse guide and query features\n",
        "    \"\"\"\n",
        "    \n",
        "    # mask support by annotations\n",
        "    pos_feats = mask_feat(sfeatures, pos_anno)\n",
        "    neg_feats = mask_feat(sfeatures, neg_anno)\n",
        "\n",
        "    # global pool support +/- features\n",
        "    # Note: This code implements ont-shot learning. When solving for few-shot learning, the pooling is done across batch dimension(0) as well\n",
        "    pos_vec = tf.reduce_sum(pos_feats, axis = (1,2))\n",
        "    neg_vec = tf.reduce_sum(neg_feats, axis = (1,2))\n",
        "\n",
        "    h, w = qfeats.shape[1:-1]\n",
        "\n",
        "    # Tile the pooled features across the image feature\n",
        "    pos_glob = tf.tile(tf.reshape(pos_vec, shape = (-1, 1, 1, tf.shape(pos_vec)[-1])), (1, h, w, 1))\n",
        "    neg_glob = tf.tile(tf.reshape(neg_vec, shape = (-1, 1, 1, tf.shape(neg_vec)[-1])), (1, h, w, 1))\n",
        "    x = tf.concat([qfeats, pos_glob], axis=-1)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbuMX-IFISj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function that retrieves mean Intersection Over Union score given two masks\n",
        "def get_miou(y, y_pred):\n",
        "  y_pred = tf.nn.sigmoid(y_pred)\n",
        "  y = tf.convert_to_tensor(y)\n",
        "  union = tf.reduce_sum(tf.cast(tf.logical_or(tf.greater_equal(y, 0.5), tf.greater_equal(y_pred,0.5)), dtype = 'int64'), axis = (1,2,3))\n",
        "  intersection = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y, 0.5), tf.greater_equal(y_pred,0.5)), dtype = 'int64'), axis = (1,2,3))\n",
        "  miou = tf.reduce_mean(tf.divide(intersection,union))\n",
        "  return miou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4g1e2jhBIpiz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upsampler\n",
        "decoder = Interpolator(1, 32, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I0O6uQwfBx3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Downsampler\n",
        "anno_enc = Downsampler(1, 32, odd = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0zAuWxSe93x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Revolver model\n",
        "sfeatures = encoder(simg_batch)\n",
        "c = K.constant(1e-6)\n",
        "pos_anno = anno_enc(smskp_batch)\n",
        "neg_anno = anno_enc(smskn_batch)\n",
        "pos_anno = tf.divide(pos_anno, tf.math.add(tf.reduce_sum(pos_anno, axis=(1,2,3)), c)[...,None, None, None])\n",
        "neg_anno = tf.divide(neg_anno, tf.math.add(tf.reduce_sum(neg_anno, axis=(1,2,3)), c)[...,None, None, None])\n",
        "qfeatures = encoder(qimg_batch)\n",
        "combined = get_combined_feat(qfeatures, sfeatures, pos_anno, neg_anno, num_classes, update = False)\n",
        "score = head(combined)\n",
        "segmentation_mask = decoder(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSLuexSJ6hGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = qmsk_batch, logits=segmentation_mask))\n",
        "\n",
        "# Define an optimizer \n",
        "train_op = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A54vpl8Hkkue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Colab visualization code\n",
        "#from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "tf.summary.scalar('loss', loss)\n",
        "tf.summary.scalar('max', tf.reduce_max(segmentation_mask))\n",
        "tf.summary.scalar('min', tf.reduce_min(segmentation_mask))\n",
        "tf.summary.scalar('mIOU', get_miou(qmsk_batch, segmentation_mask))\n",
        "summary = tf.summary.merge_all()\n",
        "#tbc = TensorBoardColab()\n",
        "#writer = tbc.get_writer()\n",
        "writer = tf.summary.FileWriter('/content/summary/train', sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8IlRMMth6hGI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(init_training)\n",
        "for i in range(50000):\n",
        "    s, loss_value, _ = sess.run([summary, loss, train_op])\n",
        "    writer.add_summary(s,i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NtGqT_xRwa4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mrf_depth import improve_segmentation_with_depth\n",
        "\n",
        "def calc_iou(pred, out):\n",
        "  \"\"\"\n",
        "  Calculates Intersection over Union between predicted mask and ground truth\n",
        "  \"\"\"\n",
        "  out_bool = out > 0.5\n",
        "  pred_bool = pred > 0.5\n",
        "  return np.sum( out_bool & pred_bool, axis=(1,2,3) ) / np.sum( out_bool | pred_bool, axis=(1,2,3) )\n",
        "  \n",
        "def measure_iou(sess, num_of_batches=-1):\n",
        "  \"\"\"\n",
        "  runs the network for the dataset and measures network's performance for the dataset in terms of mIoU\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  n = 0\n",
        "  iou = 0\n",
        "  iou_wd = 0\n",
        "  while True:\n",
        "    try:\n",
        "      p, o, d = sess.run([segmentation_mask, qmsk_batch, qdepth_batch])\n",
        "      pwd = []\n",
        "      for i in range(len(p)):\n",
        "        pwd.append(improve_segmentation_with_depth(p[i][:, :, 0], d[i][:, :, 0])/255.0)\n",
        "      pwd = np.expand_dims(pwd, -1)\n",
        "      n += len(p)\n",
        "      iou += np.sum( calc_iou(p, o) )\n",
        "      iou_wd +=  np.sum( calc_iou(pwd, o) )\n",
        "      count += 1\n",
        "      if count == num_of_batches:\n",
        "        break\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break\n",
        "  return iou/n, iou_wd/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NuKRk3n_J1-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "sess.run(init_testing)\n",
        "m = measure_iou(sess)\n",
        "print(f\"Testing Mean IOU: {m[0]}, using MRFs: {m[1]}\")\n",
        "sess.run(init_ktesting)\n",
        "m = measure_iou(sess)\n",
        "print(f\"Testing (known classes) Mean IOU: {m[0]}, using MRFs: {m[1]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}